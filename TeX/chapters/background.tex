\section{Background}

In the setting of modern data centers and HPC clusters, there have been numerous research efforts
to enhance performance. Data Analytics applications that rely on machine and deep learning techniques demand
tremendous workloads with their need for massive computing performance, and have led to the wide adoption of graphics
processing units (GPU) accelerator and multicore (CPU) technologies, which are pushing current datacenter interconnect
and memory architectures to their limit\cite{shalfHPCInterconnectsEnd2019}.

Furthermore, communication using conventional ethernet fabric is a severe inhibitor to efficient resource sharing.
For emerging compute intensive and resource hungry applications, substantial increases in bandwidth are a necessity\cite{shalfHPCInterconnectsEnd2019}.

A shift towards high speed network fabrics has been proven useful,
because it helps alleviaite the latencies that may arise from node to node communication.
The usage of InfiniBand fabrics over Ethernet fabrics is common in such setting.

The amount of time that a processor is engaged in the transmition or reception of a message, also known as overhead,
can also play a major role in performance, since the processor cannot perform other operations.
This is especially true for applications that are heavy on read/write operations, as they can
be slowed down significantly by high overheads\footnote{Overhead}\cite{martin97}.

To tackle this problems, a common solution applied in industry is the usage of InfiniBand, which
is a network architecture which supports RDMA.
RDMA works by letting the Network Interface Card (NIC) and the User Application (more specifically, its memory)
directly communicate with each other, therefore bypassing the Operating System (which is known for
causing high overhead through context switches to kernel space) and thus offloading the CPU. This practice has been
gaining traction in the HPC environment, aiding multiple machines to mitigate bottlenecks and efficiently act like a
single large system.

Taking advantage of the InfiniBand architecture requires specialized hardware, as the InfiniBand network architecture defines
its own protocols for each network layer. Moreover, special NICs, which go by the name of Channel Adapters (CA) in the InfiniBand
architecture are also required. Specifically, A CA is a programmable DMA engine which special protection features that allow
DMA operations to be initated locally and remotely\cite{infinibandvol107}.



%%  take again the main argument talking about softroce and its importance
%%  with possibly more details.
%%
%%  introduce the linux kernel, and talk about relevance of
%%  understanding the compiling process and specific options for this
%%  work.
%%
%%  directly afterwards, talk about device drivers and previous approaches
%%  made to pursue bug free software in this domain, go into fuzzing
%%
%%  explain fuzzing in depth, with specific regard to dev drivers and or
%%  SoftRoCE, talk about well known fuzzers and their limitations in
%%  respect to device drivers / rdma.
%%
%%  talk specifically about projects that use fuzzing to test
%%  device drivers, what have they achieved, what are their limitations
%%
%%  talk about my approaches and what have I achieved

\subsection{The Linux Kernel}


As the SoftRoCE driver operates as a subsystem in the linux kernel, it is pertinent to briefly
discuss the implications encompassed by this.

Similar to most Unix kernels, the linux kernel is of monotithic nature. All kernel layers
are integrated into a single program, all of which run under the kernel's privileged execution
mode. As a consquence of this, and since security checks are only enforced by the kernel code,
if there are secutiry vulnerabilities inside the kernel, then the whole system has vulnerabilities.

One main feature of the linux kernel is its ability to extend its functionality during runtime using
modules. Modules are pieces of code that can be dynamically linked or unlinked at runtime,
adding functionality to the kernel\cite{korbethLinuxDeviceDrivers2005}.

During the process of kernel configuration, device drivers required for InfiniBand support can
be compiled as built-in or as modules (Along SoftRoCE, userpace MAD support,
userspace access (verbs), among others, are required). This should make no difference for our assessment
about bugs and vulnerabilities for the reasons explained above.


\subsection{Fuzzing}

In a nutshell, fuzzing is an approach to software testing where the system being tested is bombarded with test cases generated with another program. The system is then monitored for any flaws exposed by the processing of
this input\cite{mcnallyFuzzingStateArt2012}.

Generally, this test cases consist of increasingly random modified otherwise valid inputs. Although modern
fuzzers do not rely solely on randomness for test case generation, the simplicity of this idea yielded high
effectiveness: fuzzing is still a widely applied technique between both security and quality assurance experts.
It has discovered a considerable amount of bugs over the years.


%% Software testing is a tool used in software production pipelines, its main goal is to ensure proper program functioning. One common way to test programs is
%% positive testing, in which these are tested against expected inputs under well defined scenarious (test cases), to produce the desired results.
%% Fuzzing is a technique used for negative testing, as opposite to the one just mentioned, in which the program is put under malformed or non-expected input. this
%% has lead to the discovery of many bugs in the recent years (TODO:\@ cite OSS website from lecture)

\subsubsection{Types of Fuzzers}

A program that generates input for another program to process, delivers the input and monitors the program
is called a fuzzer. Fuzzers consist of different components, which will be discribe later.

One important aspect for categorizing fuzzers is code coverage, measuring code coverage is usually implemented
with help of compiler instrumentation techniques. In such case, code coverage is measured by the number of
basic blocks reached by program execution given a \textbf{specific input}. Efficient fuzzers are capable of producing inputs that reach high coverage.

Fuzzers can be categorized into 3 main types:

\begin{itemize}
    \item Blackbox Fuzzer: No knowledge of target program internals, the testing process is limited to observing the target's input and output behaviour. Consequently, they have no means of measuring coverage and can only provide input to the target.
    \item Whitebox Fuzzer: These fuzzers can take advantage of the source code of the target application, not allowing them better insights into how the system works, but also to benefit from coverage measurements.
      %% these fuzzers rely on the knowledge of the source code of the target application, making them more efficient ( TODO: symbolic execution tools, model checkers that improve coverage, computed coverage guides the generator)
    \item Graybox Fuzzer: This applies to fuzzers that do not fall into any of the previous categories. Source code of the target may not be available, but other means of inspection such as reverse engineering, static analysis, or executing inside a debugger are the usual workhorses of graybox fuzzers\cite{mcnallyFuzzingStateArt2012}.
\end{itemize}


Along with coverage, depth is also an important metric when evaluating fuzzing efficiency. A program
might reject a test case if, for example, the computed checksum is not equal to the checksum encountered
in a fabricated packet. A later step further might reject the input because a header section does not conform
to a specific standart. Reaching further stages past  checks inside a program corresponds to reaching greater
depths, which is obviously benefitial for succesful fuzzing.

\subsubsection{Fuzzer components}

Modern fuzzers are composed of the following components:

\paragraph{Fuzz Generator:}

A fuzz generator is in charge of creating test inputs to run on the system under test. Different
approaches serve this purpose\cite{mcnallyFuzzingStateArt2012}:

\begin{itemize}\label{ss:fuzzer-components}
    \item Mutative fuzzer: the idea is to start with a sample input or a set of inputs, and \
    modify a part of it. This set of inputs is commonly refered to as the \textbf{input corpus}; the mutative approach is useful for inputs that must conform to defined structures, coverage is not
    always good. A positive aspect of this type of generators is that they do not require protocol knowledge.
    \item Generative fuzzer: generate inputs from scratch. This can yield higher coverages, at the cost of requiring
    knowledge of protocols. It can be based on templates or grammars.
\end{itemize}

These two main categories can be further described by the techniques used to generate their data:

\begin{itemize}
    \item Oblivious: generates or mutates data randomly, this brings of course poor coverage.
    \item Template based: provided an input template, the fuzzer will only modify/generate specific parts \
    allowed by the template.
    \item Block based: represent data as nested data blocks of varying types as opposed to string sequences.
    \item Grammar based: make use of a previously given grammar, to generate input.
    \item Protocol fuzzer: knows about concepts such as replies and responses, and in which \
    sequence to reply responses in order to test certain functionality.
\end{itemize}

\paragraph{Coverage guided fuzzing}

Generation or Mutation based on coverage is described by the algorithm in listing~\ref{lst:genalg}.

%% maybe flow diagram replacing this listing and also highlight importance with an if cascade program.
%% mention afl creating valid jpegs out of nothing


\begin{lstlisting}[caption={Coverage based data generation}, label={lst:genalg}, language=python]
    # First step: acquire initial corpus
        while(True):
            MutateCorpus()
            Run(newInputs)
            if (coverage > coverageOld)  Corpus.add(newInput)

\end{lstlisting}


\paragraph{Delivery Mechanisms}

A delivery mechanism is a fuzzer component which is in charge of presenting input (from the generator)
to the system under test. Normally, as finding abnormal functioning during regular operation of the
target program is aimed at, Fuzzers use delivery mechanisms simulate those used by the system under test\cite{mcnallyFuzzingStateArt2012}.

Delivery mechanisms are usually one of:

\begin{itemize}
    \item Files
    \item Environment variables
    \item Invocation parameters (command-line or API)
    \item Network transmissions
    \item Operating system events (including mouse and keyboard events)
    \item Operating system resources
    \item Direct memory injection (risk to corrupt state and abort program)
\end{itemize}

% (TODO: expand more on this based on which one is chosen)

\paragraph{Monitoring Frameworks}

Detecting that the system under test has crashed as a result of some input is essential to the fuzzing process.
There are two broad classes of monitoring frameworks\cite{mcnallyFuzzingStateArt2012}:

\begin{itemize}
    \item Local monitoring: the fuzzer is installed in the same system as the target. It may look for additional output \
    from the target (such as core dump files) in order to assert that the target has encountered errors.
    \item Remote monitoring: more limited that their counterpart by nature, remote monitowring frameworks recognize \
    a failure by looking for network interruptions.
\end{itemize}

%% IMPORTANT: Fuzzing linux kernel, explain compile options relevant for fuzzing
\subsection{Fuzzing the linux kernel}
%% https://youtu.be/YwX4UyXnhz0?t=452
%%

As opposed to userspace fuzzing, fuzzing the linux kernel
presents some challenges and limitations. As an example, in single threaded
userspace applications, coverage is a function of the input, it has a
deterministic behaviour; collecting coverage for the kernel however, is
very different;  the kernel contains a high degree
non-deterministic behavior. In \cite{okechInvestigatingExecutionPath2013}, a
simple test program consisting of an open and a read system call revealed
559 distinct execution paths, which were mainly attributed to interrupts and context switches.
% without interrupt and switches 33 unique paths

Finding races is another desirable outcome in this scenario. This is
challenging because this kind of bugs depend on exact
execution interleavings of threads to be triggered, they are consequently hardly reproduceable if the testing method does not account for deterministic
thread interleavings.

Despite this challenges, fuzzing has proven to be excelent approach to testing the
kernel's code base: the system call fuzzer syzkaller alone has discovered
almost  4000 bugs since the time it has been operational as a continous
automated fuzzer\cite{Syzbot}.

The following configuration options are relevant when fuzzing the kernel:

\begin{itemize}
\item The Kernel Address Sanitizer (KASAN): Using compiler instrumentation, validity checks are inserted to memory accesses, thus revealing memory safety errors such as \
  out-of-bound access and use-after-free. For better error reports containing stack traces, one can also enable the option CONFIG\_STACKTRACE along KASAN\cite{KernelAddressSanitizer}.
\item Kcov: kcov exposes coverage information for the kernel in a form suitable for coverage-guided fuzzing. Coverage data is exposed via the kcov debugfs file, located under /sys/kernel/debug/kcov. Kcov \
  aims not to collect as much coverage as possible, but stable coverage (function of the input), by disabling coverage collection from interrupts and from non-deterministic parts of the kernel\cite{KcovCodeCoveragea}
\end{itemize}

%%
%% despite of this difficulties, talk about limitations of compiler based tools: they cannot discover many errors past more obvious ones.

%%
%%
%% TODO: remove or rewrite this section, it sucks.
%% \subsection{Fuzzers REMOVE OR REWRITE}

%% There are well over dozens of open source fuzzing tools and libraries \cite{awesome-fuzzing}, but the purpose of this work, the following
%% are well worth mentioning:
%% % TODO: in each section, why not chosen.


%% \paragraph{AFL}

%% The American Fuzzy Lop fuzzer is a brute force fuzzer that uses instrumentation guided coverage to
%% efficiently fuzz the system under test \cite{afl}. AFL can operate as a white-box fuzzer (source code is availabljkke)
%% to achieve best results, this requires compiling the source code with a drop in replacement for gcc/clang
%% called afl-gcc.


%% \paragraph{Libfuzzer}

%% Libfuzzer is a coverage guided evolutionary fuzzing engine, it was designed with the intent to fuzz
%% libraries, feeding fuzzed inputs to an entry point (target function). In order to achieve this Libfuzzer
%% is linked with the library under test. It can be combined with AFL for example, this would require both processes to be
%% periodically restarted in order to 'use' each others findings \cite{libfuzzer}.


%% \paragraph{kAFL}

%% % problem: requires intel PT
%% % TODO: clean up this section.

%% As AFL is limited to userspace and lacks support for kernel space\cite{kafl}, kAFL was designed with overcoming
%% the obstacles that are inherent when fuzzing kernels: kernel crashes (panics) usually make the host operating system
%% unavailable, collecting coverage from a broken system is neither possible, nor perhaps desired.

%% The inherent non-determinism in kernel level programs: kernel threads, statefulness and similar mechanisms. (libfuzzer)
%% this makes fuzzing kernel code challenging.

%% coverage information is provided by Intel's Processor Trace (PT) technology. Logic used to perform
%% mutations and scheduling closely resembles the one used in AFL\cite{kafl}

%% \paragraph{Syzkaller}

%% Syzkaller is a fuzzing framework designed to fuzz kernels at the system call level. It operates on multiple
%% virtual machines and collects coverage information using KCOV. Syzkaller also comes with a systemcall specification
%% language (syzlang), designed to aid in targetting specific subsystems inside kernels \cite{syzkaller}.

\subsection{RDMA-aware applications}

In RDMA-aware applications, the program consumes the verbs API contained in the libibverbs library\footnote{\url{https://github.com/linux-rdma/rdma-core}}.
The API handles the control path for creation, modification, querying and destruction of resources used by RDMA applications.

For the control path, the library uses system calls that are handled by file operations on device nodes
registered by the uverbs kernel module. The kernel module passes control down to lower level drivers.
These lower level drivers can be drivers for real hardware, or software drivers, like SoftRoCE.

In contrast to the control path,  the library implements the data path with calls that are made
directly to the low level drivers, enabling the kernel bypass\cite{}.

The queue pair one of the most important resources created by RDMA applications. It represents an end node
in a communication channel and represents state of the application by the queue pair state machine:

There are different types of queue pairs:
\begin{itemize}
  \item RC
  \item UC
\end{itemize}


%% Queue pairs are the main actors in ibverbs applications. You can compare the queue pair
%% to a socket in traditional network programming, as queue pairs represent a connection as much as sockets do.




%% ibverbs, library for rdma aware apps

%% what is difficult to fuzz about rdma apps

\subsubsection{Transpor Layer: The Base Transport Headers} % OR: role of the device driver before

One of the tasks of low level drivers for RDMA devices is to process
packet headers of the transport layer protocol. This task roughly consists
of assigning a queue pair to the packet, performing requested operations like
read or write and performing sanity checks.

These transport layer headers are called
base transport headers, and contain information describing the
requested operation and the  destination queue pair.

There are also header extensions for the base headers, but their presence is dictated
by the operation code. We will focus in this section on base transport headers,
because they are common to all RDMA traffic.

Base transport headers are 96 bits long, Table
\ref{tab:bthfields} shows the corresponding field descriptions. The order in which fields
are listed in Table \ref{tab:bthfields} coincide with the layout of the actual header.

\begin{table}[h]
  \begin{tabular}{|| m{10em} | m{4em} | m{3em} | m{15em} ||}
    \hline
    Field Name & Field Abbreviation & Field Size (bits) & Description\\
    \hline
    Opcode & OpCode & 8 & Indicates the packet type, also specifies which extension headers follow the base transport header.\\
    \hline
    Solicited Event & SE & 1 &  The requester sets this bit to 1 to specify that the responder shall invoke the Completion Queue event handler.\\
    \hline
    MigReq & M & 1 &  Used to communicate Path Migration State, path migration refers to both communication partners agreeing to use a new communication path\\
    \hline
    Pad Count & PadCnt & 2 &  Number of pad bytes added to the headers to align the payload to a 4 byte boundary.\\
    \hline
    Transport Header Version & TVer & 4 &  Specifies the Transport version used for the packet, it is set to 0x0.\\
    \hline
    Partition Key & P\_KEY & 16 &  Partitioning allows isolation among systems sharing the same fabrics. If using partition, this field is required to match partition key stored at the receiver or else the packet will be discarded\\
    \hline
    Reserved (variant) & & 8 &  transmited as 0s, this field is ignored on the receiver side.\\
    \hline
    Destination QP & DestQP & 24 &  specifies a number to identify the destination queue pair.\\
    \hline
    Acknowledge Request & A & 1 &  If this bit is set, responder should schedule an acknowledgment packet on the associated queue pair.\\
    \hline
    Reserved & & 7 &  transmited as 0s, ignored by receiver. \\
    \hline
    Packet Sequence Number & PSN & 24 &  Identifies the position of a packet in a sequence of packets, used e.g. to recognized lost packets.\\
    \hline
  \end{tabular}
  \caption[Base Transport Header Fields]{Base Transport Header Fields, adapted from\cite{infinibandvol107}}
  \label{tab:bthfields}
\end{table}

%% why? explain queue pair state machine, show states requiring a connection
\subsubsection{Challenges posed for fuzzing}\label{s:ibverbs-challenges}

Reaching full coverage for ibverbs applications is not trivial. In order to perform RDMA operations, establishment of
a connection to the remote host, as well as appropriate permissions need to be set up first. The mechanism for accomplishing
these tasks is the queue pair\cite{rdmamanual}. A connected queue pair
needs information from the remote queue pair in order to transition to a ready state.
For connected queue pair types, ready states represent connected queue pairs.

At the time the device driver checks the base transport headers, it will also assert if there is an existing queue pair
with the qpn found in the headers. It will also check if this queue pair is in a ready state; if any these conditions
are not met, the driver will drop the packet.

This means that a fuzzing application should either let 2 applications initialize and reach a ready state,
or lead the target application to think it has connected with another application. After either condition is true,
fuzzing can discover bugs that are tied to a ready state.



% \subsubsection{Programming with ibverbs}

%% TODO how does it work, basics, state machine
%% specific bug => requires a specific state



%% It is pertinent to evaluate some aspects of linux and the kernel as the nature of
%% the system in which the SoftRoCE driver operates, allows its code to operate
%% under the most privileged level, along the kernel itself.

%% One of the main features of the linux kernel is its ability to extend
%% its functionality during runtime. Code that can be added (or removed) to the kernel
%% while is running are called modules. Each module is made of object code that can
%% be dynamically linked with the insmod or modprobe executables\cite{ldd3}.

%% Security checks in linux are enforced in the kernel code, if there are security vulnerabilities inside
%% the kernel, then the whole system has vulnerabilities.\cite{ldd3}

% Talk about the linux kernel being expandable by modules, which operate on
% so called `kernel space` or privileged mode, this makes them in turn mandatory
% to be well tested, because a malfunctioning module in this case a device 
% driver a potential target inside the system.

% TODO: move this to methodology
%% When compiling the linux kernel, we want to enable support for the InfiniBand network stack, virtualization and
%% also builtin functionality that will come to aid during the fuzzing process, the following are worth
%% mentioning:

%% \begin{itemize}
%%     \item Kcov: Code coverage for fuzzing. From \cite{kerneldocs-kcov} Kvoc exposes kernel code coverage information in a form suitable\
%%     for coverage-guided fuzzing (randomized testing). Coverage data of a running kernel is exported via\ Background
%%     a debugfs file called kcov. % TODO:
%%     % NOTE ON KCOV profiling data will only become accesibleonce debugfs has been mounted mount -t debugfs none /sys/kernel/debug
%%     \item KASAN: The Kernel Address Sanitizer is a dynamic memory error detector. It provides\
%%     information for finding use-after-free and out-of-bound bugs, it uses compiler generated\
%%     instrumentation code to check every memory access \cite{kerneldocs-kasan} % TODO:
%%     \item Fault Injection: interest to test error handling paths of IO operations, malloc, futex calls, etc: reason => a big portion of kernel code is concerned with error handling operations. => related work
%%
%% \end{itemize}

%% TODO: mention UBSAN and KCSAN


%% \subsection{RDMA with Infiniband}

%% RoCE is a standard for RDMA over Ethernet, which allows leveraging RDMA semantics over an Ethernet network without needing
%% to resort to TCP transport.
%% % According to \cite{rdmamanual} RoCE provided the most efficient low lattency Ethernet solution to the day of (their?) writing (in 2015).
%% % TODO: maksym => just say that RoCE is generally cheaper because it does not require specialized switches.
%% \paragraph{Rxe: Soft-RoCE}

%% Soft-RoCE is a software implementation of the RDMA transport (over Ethernet), it has been developed as a github
%% community project, with help from IBM, Mellanox and other companies.This software driver provides us an
%% uncomplicated manner to test RDMA technologies without needing to use real hardware, it provides a complete RDMA
%% stack implementation over any NIC \cite{mellanox-community}.

%% % running \\ \$ modinfo rdma\_rxe \\ inside the shell, reveals that this module depends on the following modules: ib\_core, ip6\_udp\_tunnel, udp\_tunnel, ib\_uverbs
%% % all which are as well loaded into the kernel when issuing the command \\ \$ modprobe rdma\_rxe \\
%% % modprobe loads a module into the kernel, while also loading the modules on which it depends on \cite{ldd3}.
%% % TODO: Maksym => this definitely does not go into the main body of the text, if you are so eager to conclude it, use appendecies.

%% % udev is a program that enables Linux to provide a persistent device-naming system
%% % in the /dev directory \cite{kroah-hartman06}

%% % To get Soft-RoCE capabilities, you need to install the kernel and user space libraries on both servers:
%% % We are mainly interested in the rdma\_rxe kernel module, Software RDMA over Ethernet, provides a software implementation of the RoCEv2 Protocol, cite manpages.


%% % TODO: is this necesary? are we using specifically InfiniBand technology? => modules are listed under /drivers/infiniband, so Ill guess yes


%% % running \\ \$ modinfo rdma\_rxe \\ inside the shell, reveals that this module depends on the following modules: ib\_core, ip6\_udp\_tunnel, udp\_tunnel, ib\_uverbs

%% % all which are as well loaded into the kernel when issuing the command \\ \$ modprobe rdma\_rxe \\
%% % modprobe loads a module into the kernel, while also loading the modules on which it depends on \cite{ldd3}.


%% % udev is a program that enables Linux to provide a persistent device-naming system
%% % in the /dev directory \cite{kroah-hartman06}

%% % To get Soft-RoCE capabilities, you need to install the kernel and user space libraries on both servers:
%% % We are mainly interested in the rdma\_rxe kernel module, Software RDMA over Ethernet, provides a software implementation of the RoCEv2 Protocol, cite manpages.
